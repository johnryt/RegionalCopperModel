{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-packages-and-functions\" data-toc-modified-id=\"Import-packages-and-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import packages and functions</a></span></li><li><span><a href=\"#Import-data-and-parameters\" data-toc-modified-id=\"Import-data-and-parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import data and parameters</a></span></li><li><span><a href=\"#Historical-initialization\" data-toc-modified-id=\"Historical-initialization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Historical initialization</a></span></li><li><span><a href=\"#Multi-Scenario-Simulations\" data-toc-modified-id=\"Multi-Scenario-Simulations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Multi-Scenario Simulations</a></span></li><li><span><a href=\"#Previously-run-scenarios\" data-toc-modified-id=\"Previously-run-scenarios-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Previously-run scenarios</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T18:00:31.968549Z",
     "start_time": "2021-01-27T18:00:30.705889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "idx = pd.IndexSlice\n",
    "import random\n",
    "from gurobipy import *\n",
    "\n",
    "from cn_mine_simulation_tools import *\n",
    "from cn_refinery import *\n",
    "from cn_scrap_supply_tools import *\n",
    "from cn_demand_tools import *\n",
    "from cn_price_formation import * \n",
    "from cn_blending import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # to deal with pandas datetime deprecation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'asscalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jryter\\OneDrive - DOI\\Documents\\generalizationOutside\\RegionalCopporModel\\China - Integration and scenarios - W.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jryter/OneDrive%20-%20DOI/Documents/generalizationOutside/RegionalCopporModel/China%20-%20Integration%20and%20scenarios%20-%20W.ipynb#W4sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m product_lifetime\u001b[39m=\u001b[39mproduct_life_and_eff\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mLifetime\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jryter/OneDrive%20-%20DOI/Documents/generalizationOutside/RegionalCopporModel/China%20-%20Integration%20and%20scenarios%20-%20W.ipynb#W4sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m product_lifetime_cn \u001b[39m=\u001b[39m product_life_and_eff\u001b[39m.\u001b[39mloc[:, \u001b[39m'\u001b[39m\u001b[39mCN Lifetime\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jryter/OneDrive%20-%20DOI/Documents/generalizationOutside/RegionalCopporModel/China%20-%20Integration%20and%20scenarios%20-%20W.ipynb#W4sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m product_lifetime_df\u001b[39m=\u001b[39mlifetime_df(product_lifetime)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jryter/OneDrive%20-%20DOI/Documents/generalizationOutside/RegionalCopporModel/China%20-%20Integration%20and%20scenarios%20-%20W.ipynb#W4sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m product_lifetime_df_cn \u001b[39m=\u001b[39m lifetime_df(product_lifetime_cn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jryter/OneDrive%20-%20DOI/Documents/generalizationOutside/RegionalCopporModel/China%20-%20Integration%20and%20scenarios%20-%20W.ipynb#W4sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m product_lifetime_freq_df\u001b[39m=\u001b[39mlifetime_freq_df(product_lifetime_df)\n",
      "File \u001b[1;32mc:\\Users\\jryter\\OneDrive - DOI\\Documents\\generalizationOutside\\RegionalCopporModel\\cn_scrap_supply_tools.py:25\u001b[0m, in \u001b[0;36mlifetime_df\u001b[1;34m(product_lifetime, sigma_to_mu, mu_0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m product_lifetime\u001b[39m.\u001b[39mindex:\n\u001b[0;32m     24\u001b[0m     lifetime_mean\u001b[39m=\u001b[39mproduct_lifetime\u001b[39m.\u001b[39mloc[p]\n\u001b[1;32m---> 25\u001b[0m     mu\u001b[39m=\u001b[39mcalc_mu(sigma_to_mu, mean\u001b[39m=\u001b[39;49mlifetime_mean, x0\u001b[39m=\u001b[39;49mmu_0)\n\u001b[0;32m     26\u001b[0m     product_lifetime_df\u001b[39m.\u001b[39mloc[p, \u001b[39m'\u001b[39m\u001b[39mmu\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mmu\n\u001b[0;32m     27\u001b[0m     product_lifetime_df\u001b[39m.\u001b[39mloc[p, \u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mmu\u001b[39m*\u001b[39msigma_to_mu\n",
      "File \u001b[1;32mc:\\Users\\jryter\\OneDrive - DOI\\Documents\\generalizationOutside\\RegionalCopporModel\\cn_scrap_supply_tools.py:15\u001b[0m, in \u001b[0;36mcalc_mu\u001b[1;34m(sigma_to_mu, mean, x0, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_mu\u001b[39m(sigma_to_mu, mean, x0, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masscalar(fsolve(lognorm_mean, x0\u001b[39m=\u001b[39mx0, args\u001b[39m=\u001b[39m(sigma_to_mu, mean), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\jryter\\AppData\\Local\\anaconda3\\envs\\mining\\lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'asscalar'"
     ]
    }
   ],
   "source": [
    "## High level parameters\n",
    "historical_prod=pd.read_excel('Data/Production data compile.xlsx', sheet_name='Selected', index_col=0).loc[:2018]\n",
    "historical_prod_cn=pd.read_excel('Data/Production data compile.xlsx', sheet_name='China', index_col=0, usecols='A:O,W:X,AE').loc[:2018]\n",
    "historical_prod_rw = historical_prod.loc[1950:] - historical_prod_cn.loc[1950:]\n",
    "raw_price=pd.read_excel('Data/Price data compile.xlsx', sheet_name='Price', index_col=0) # All prices 2017 constant\n",
    "raw_price.drop(['Grape','Low_brass','Pb_Red_Brass'], axis = 1, inplace = True)\n",
    "\n",
    "# Specific prod and mine data\n",
    "historical_mining_prod=historical_prod.loc[:, 'Total mining production']\n",
    "historical_mining_prod_cn = historical_prod_cn.loc[:, 'Total mining production']\n",
    "historical_mining_prod_rw = historical_prod_rw.loc[:, 'Total mining production']\n",
    "\n",
    "## Primary supply data and patameters\n",
    "operating_mine_pool=pd.read_excel('Data/primary supply/Operating mine pool - countries.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "open_parameter=pd.read_excel('Data/primary supply/Opening subsample parameter.xlsx', sheet_name='max5', index_col=0)\n",
    "incentive_pool=pd.read_excel('Data/primary supply/Incentive mine pool - countries.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "pri_hyper_param=pd.read_excel('Data/primary supply/Hyperparameters.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "operating_mine_pool_cn = operating_mine_pool.loc[operating_mine_pool.loc[:, 'Country'] == 'China']\n",
    "operating_mine_pool_rw = operating_mine_pool.loc[operating_mine_pool.loc[:, 'Country'] != 'China']\n",
    "incentive_pool_cn = incentive_pool.loc[incentive_pool.loc[:, 'Country'] == 'China']\n",
    "incentive_pool_rw = incentive_pool.loc[incentive_pool.loc[:, 'Country'] != 'China']\n",
    "\n",
    "## Refinery parameters\n",
    "ref_hyper_param=pd.read_excel('Data/refined supply/Refinery hyperparameter.xlsx', sheet_name='Parameters', index_col=0)\n",
    "ref_hyper_param_cn = pd.read_excel('Data/refined supply/Refinery hyperparameter.xlsx', sheet_name='CN Parameters', index_col=0)\n",
    "ref_hyper_param_rw = pd.read_excel('Data/refined supply/Refinery hyperparameter.xlsx', sheet_name='RW Parameters', index_col=0)\n",
    "conc_to_cathode_eff=ref_hyper_param.loc['conc to cathode eff', 'Value']\n",
    "scrap_to_cathode_eff=ref_hyper_param.loc['scrap to cathode eff', 'Value']\n",
    "ref_prod_history = historical_prod.loc[1960:, 'Primary refining production':'Refined usage'].copy()\n",
    "ref_prod_history_cn = historical_prod_cn.loc[1960:, 'Primary refining production':'Refined production, WoodMac'].copy()\n",
    "ref_prod_history_cn.columns = ref_prod_history.columns\n",
    "ref_prod_history_rw = ref_prod_history - ref_prod_history_cn\n",
    "historical_ref_imports_cn = pd.Series(0,index=np.arange(1960,2041))\n",
    "historical_ref_imports_cn.loc[:2018] = historical_prod_cn.loc[:, 'Net Refined Imports'].copy()\n",
    "historical_ref_imports_cn.loc[2019:] = historical_ref_imports_cn.loc[2018]\n",
    "historical_ref_imports_cn.loc[:1974] += historical_prod_cn.loc[:1974,'Semis Imports (COMTRADE, kt)']\n",
    "\n",
    "## Semis demand parameters\n",
    "gdp_growth_prediction_base=pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='GDP growth', index_col=0, usecols=np.arange(6))\n",
    "volume_prediction_base=pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='All sectors', index_col=0, header=[0,1])\n",
    "intensity_prediction=pd.read_excel('Data/semis demand/Intensity initial.xls', sheet_name='Sheet1', index_col=0, header=[0,1])\n",
    "elas_sec_reg=pd.read_excel('Data/semis demand/Elasticity estimates.xlsx', sheet_name='S+R S intercept only', index_col=0)\n",
    "sector_shape_matrix=pd.read_excel('Data/semis demand/Sector to shape matrix updated.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "calibration_1718=pd.read_excel('Data/semis demand/2017 and 2018 calibration.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "\n",
    "# Adjust demand in 2018 to scale it back to ICSG\n",
    "intensity_prediction.loc[2017, :] = intensity_prediction.loc[2017, :]\\\n",
    ".mul(calibration_1718.loc[2017, 'ICSG refined usage']).div(calibration_1718.loc[2017, 'simulated refined usage'])\n",
    "intensity_prediction.loc[2018, :] = intensity_prediction.loc[2018, :]\\\n",
    ".mul(calibration_1718.loc[2018, 'ICSG refined usage']).div(calibration_1718.loc[2018, 'simulated refined usage'])\n",
    "demand_prediction=volume_prediction_base.loc[2015:, :].mul(intensity_prediction.fillna(0))\n",
    "\n",
    "## Scrap supply parameters\n",
    "use_sector_combined=pd.read_excel('Data/scrap supply/End use combined data.xlsx', sheet_name='Combined', index_col=0)\n",
    "sector_to_product=pd.read_excel('Data/scrap supply/All accounting matrix.xlsx', sheet_name='sector to product', index_col=0)\n",
    "product_to_waste=pd.read_excel('Data/scrap supply/All accounting matrix.xlsx', sheet_name='product to waste', index_col=0)\n",
    "product_life_and_eff=pd.read_excel('Data/scrap supply/All accounting matrix.xlsx', sheet_name='product lifetime and efficiency', index_col=0)\n",
    "product_to_cathode_alloy=pd.read_excel('Data/scrap supply/All accounting matrix.xlsx', sheet_name='product to copper or alloy', index_col=0)\n",
    "recycle_efficiency=pd.read_excel('Data/scrap supply/All accounting matrix.xlsx', sheet_name='recycling efficiency', index_col=0)\n",
    "\n",
    "# Availability-specific parameters\n",
    "s2s = pd.read_excel('Data/Shape-Sector Distributions.xlsx', index_col=0)\n",
    "prod_spec = pd.read_excel('Data/Prod_spec_20200311_no_low.xlsx')\n",
    "raw_spec = pd.read_excel('Data/Raw_spec_201901.xlsx',index_col=0)\n",
    "raw_spec.drop(['Grape','Low_brass','Pb_Red_Brass'],inplace=True)\n",
    "for i in prod_spec.index:\n",
    "    prod_spec.loc[i,'UNS'] = prod_spec.loc[i,'UNS']+' '+prod_spec.loc[i,'Category']\n",
    "    \n",
    "# Home scrap ratio\n",
    "home_scrap_ratio_file=pd.read_excel('Data/scrap supply/Home scrap ratio.xls', sheet_name='Sheet1', index_col=0)\n",
    "home_scrap_ratio_series=home_scrap_ratio_file.loc[:, 'Calibrated ratio']\n",
    "exchange_scrap_ratio_series=0.9-home_scrap_ratio_series\n",
    "\n",
    "# Sector end use to product matrix \n",
    "use_product_history = use_sector_combined.apply(lambda x: (x*sector_to_product).sum(axis=1),axis=1)\n",
    "demand_fractions = pd.read_excel('Data/semis demand/demand_analysis_copper_lto_q2_2016.xls', sheet_name='Analysis', index_col = 0)\n",
    "cn_demand_fraction = demand_fractions.loc[:,'China Fraction']\n",
    "rw_demand_fraction = 1 - cn_demand_fraction\n",
    "use_product_history_cn = use_product_history.apply(lambda x: x*cn_demand_fraction.loc[:2018])\n",
    "use_product_history_rw = use_product_history.apply(lambda x: x*rw_demand_fraction.loc[:2018])\n",
    "\n",
    "# Product to waste matrices\n",
    "product_to_waste_collectable=product_to_waste.iloc[:, :-2]\n",
    "product_to_waste_no_loss=product_to_waste_collectable.mul(1/product_to_waste_collectable.sum(axis=1), axis=0)\n",
    "\n",
    "# Product lifetime parameters and frequencies\n",
    "product_lifetime=product_life_and_eff.loc[:, 'Lifetime']\n",
    "product_lifetime_cn = product_life_and_eff.loc[:, 'CN Lifetime']\n",
    "product_lifetime_df=lifetime_df(product_lifetime)\n",
    "product_lifetime_df_cn = lifetime_df(product_lifetime_cn)\n",
    "product_lifetime_freq_df=lifetime_freq_df(product_lifetime_df)\n",
    "product_lifetime_freq_df_cn = lifetime_freq_df(product_lifetime_df_cn)\n",
    "\n",
    "# Recycling and fabrication efficiencies\n",
    "sort_eff=recycle_efficiency.iloc[:, 0]\n",
    "sort_eff_cn = recycle_efficiency.iloc[:, 2]\n",
    "collect_rate=recycle_efficiency.iloc[:, 1]\n",
    "collect_rate_cn = recycle_efficiency.iloc[:, 3]\n",
    "fab_eff=product_life_and_eff.loc[:, 'Fabrication efficiency']\n",
    "fab_eff_cn = product_life_and_eff.loc[:, 'CN Fabrication efficiency']\n",
    "new_scrap_gen=1/fab_eff-1\n",
    "new_scrap_gen_cn = 1/fab_eff_cn-1\n",
    "sort_eff_series=pd.DataFrame(np.array((list(sort_eff)*23)).reshape(23, 6), index=np.arange(2018, 2041), columns=sort_eff.index)\n",
    "sort_eff_series_cn = pd.DataFrame(np.array((list(sort_eff_cn)*23)).reshape(23, 6), index = np.arange(2018,2041), columns = sort_eff_cn.index)\n",
    "collect_rate_series=pd.DataFrame(np.array((list(collect_rate)*23)).reshape(23, 6), index=np.arange(2018, 2041), columns=collect_rate.index)\n",
    "collect_rate_series_cn=pd.DataFrame(np.array((list(collect_rate_cn)*23)).reshape(23, 6), index=np.arange(2018, 2041), columns=collect_rate_cn.index)\n",
    "\n",
    "## Price formation parameters\n",
    "price_formation_param=pd.read_excel('Data/price formation/Price formation.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "cathode_sd_elas=price_formation_param.loc['Cathode SD elasticity', 'Value']\n",
    "conc_sd_elas=price_formation_param.loc['Concentrate SD elasticity', 'Value']\n",
    "cathode_sp2_elas=price_formation_param.loc['SP2 cathode elasticity', 'Value']\n",
    "sp2_sd_elas=price_formation_param.loc['SP2 SD elasticity', 'Value']\n",
    "cathode_sp1_elas=price_formation_param.loc['SP1 cathode elasticity', 'Value']\n",
    "sp1_sd_elas=price_formation_param.loc['SP1 SD elasticity', 'Value']\n",
    "cathode_alloyed_elas=price_formation_param.loc['SP2 SD elasticity', 'Value']\n",
    "alloyed_sd_elas=price_formation_param.loc['SP Alloy SD elasticity', 'Value']\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_initialization()\n",
    "scrap_subset = list(['Yellow_Brass','Cartridge', 'No.1', 'No.2', 'Pb_Yellow_Brass', 'Ocean', \n",
    "                    'Red_Brass', 'Al_Bronze', 'Ni_Ag'])\n",
    "# fraction_yellows is fraction of Yellow_Brass, Pb_Yellow_Brass, and Cartridge allowed in secondary refineries\n",
    "fraction_yellows = 0.05 \n",
    "# Scrap correction factor due to accumulation from prior year's unused scrap being available; maintains scrap spread following original simulation pathway\n",
    "scrap_bal_correction = 0.94\n",
    "# Post-industrial recycled material price is defined as 0.65 multiplied by No.1 scrap price, as PIR prices most closely correlate with No.1 price and 0.65 allows all PIR to be consumed, aligning with industry expectations\n",
    "pir_price_set = 0.65\n",
    "\n",
    "# Initialize simulation time\n",
    "history_start_time='19600101'\n",
    "simulation_start_time='20180101'\n",
    "simulation_end_time='20400101'\n",
    "simulation_time=pd.date_range(simulation_start_time, simulation_end_time, freq='AS')\n",
    "history_time=pd.date_range(history_start_time, simulation_start_time, freq='AS')\n",
    "\n",
    "# Cathode price\n",
    "cathode_price_series=pd.Series(0, index=history_time)\n",
    "cathode_price_series.loc[:'20180101']=historical_lme_price.values\n",
    "cathode_bal_l1 = pd.Series(0, index = np.arange(2018,2041))\n",
    "\n",
    "# TCRC\n",
    "tcrc_series=pd.Series(0, index=history_time)\n",
    "tcrc_series.loc[:'20180101']=historical_tcrc.values\n",
    "\n",
    "# Raw prices initialization\n",
    "raw_price_cn = raw_price.copy()\n",
    "raw_price_rw = raw_price.copy()\n",
    "scraps = [i for i in raw_price.columns if 'Ref' not in i and 'No.' not in i]\n",
    "\n",
    "# Scrap spreads (No.2, No.1, alloyed)\n",
    "sp2_series=pd.Series(0, index=history_time)\n",
    "sp2_series.loc[:'20180101']=historical_sp2.values\n",
    "sp2_series_cn=pd.Series(0, index=history_time)\n",
    "sp2_series_cn.loc[:'20180101']=historical_sp2.values\n",
    "sp2_series_rw=pd.Series(0, index=history_time)\n",
    "sp2_series_rw.loc[:'20180101']=historical_sp2.values\n",
    "sp1_series = pd.Series(0, index=history_time)\n",
    "sp1_series.loc[:'20180101'] = historical_sp1.values\n",
    "sp1_series_cn = pd.Series(0, index=history_time)\n",
    "sp1_series_cn.loc[:'20180101'] = historical_sp1.values\n",
    "sp1_series_rw = pd.Series(0, index=history_time)\n",
    "sp1_series_rw.loc[:'20180101'] = historical_sp1.values\n",
    "spa_series = pd.DataFrame(0, index=history_time, columns=scraps)\n",
    "spa_series.loc[:'20180101']= historical_spa.values\n",
    "spa_series_cn = pd.DataFrame(0, index=history_time, columns=scraps)\n",
    "spa_series_cn.loc[:'20180101']= historical_spa.values\n",
    "spa_series_rw = pd.DataFrame(0, index=history_time, columns=scraps)\n",
    "spa_series_rw.loc[:'20180101']= historical_spa.values\n",
    "\n",
    "# Initialize mining stats\n",
    "mine_life_stats_panel_operating=mine_life_stats_panel_init(simulation_time, operating_mine_pool)\n",
    "mine_pool_new_last=pd.DataFrame()\n",
    "mine_life_stats_panel_new_last=pd.DataFrame()\n",
    "total_mining_prod=pd.Series(0, index=simulation_time)\n",
    "\n",
    "# Initilize sxew ids\n",
    "sxew_id_operating_bool=operating_mine_pool.loc[:, 'Payable percent (%)']==100\n",
    "sxew_id_operating=[i for i in sxew_id_operating_bool.index if sxew_id_operating_bool.loc[i]]\n",
    "conc_id_operating_bool=operating_mine_pool.loc[:, 'Payable percent (%)']!=100\n",
    "conc_id_operating=[i for i in conc_id_operating_bool.index if conc_id_operating_bool.loc[i]]\n",
    "sxew_id_new_bool=incentive_pool.loc[:, 'Payable percent (%)']==100\n",
    "sxew_id_new=[i for i in sxew_id_new_bool.index if sxew_id_new_bool.loc[i]]\n",
    "conc_id_new_bool=incentive_pool.loc[:, 'Payable percent (%)']!=100\n",
    "conc_id_new=[i for i in conc_id_new_bool.index if conc_id_new_bool.loc[i]]\n",
    "\n",
    "sxew_new=pd.Series(0, index=simulation_time)\n",
    "sxew_all=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "sxew_all_cn=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "sxew_all_rw=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "sxew_all.loc['20170101']=historical_prod.loc[2017, 'SX-EW production']\n",
    "sxew_all_cn.loc['20170101']=historical_prod_cn.loc[2017, 'SX-EW production']\n",
    "sxew_all_rw.loc['20170101']=historical_prod_rw.loc[2017, 'SX-EW production']\n",
    "\n",
    "\n",
    "# Initialize refinery stats\n",
    "ref_stats=ref_stats_init(simulation_time, ref_hyper_param)\n",
    "ref_stats_cn = ref_stats_init(simulation_time, ref_hyper_param_cn)\n",
    "ref_stats_rw = ref_stats_init(simulation_time, ref_hyper_param_rw)\n",
    "ref_bal_l1 = pd.Series(0, index = np.arange(2018,2041))\n",
    "ref_bal_l1_cn = pd.Series(0, index = np.arange(2018,2041))\n",
    "ref_bal_l1_rw = pd.Series(0, index = np.arange(2018,2041))\n",
    "\n",
    "# Initialize concentrate prod, add 2017\n",
    "conc_prod_series=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "conc_prod_series_cn=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "conc_prod_series_rw=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "conc_prod_series_cn.loc['20170101']=historical_prod_cn.loc[2017, 'Concentrate production']\n",
    "conc_prod_series_rw.loc['20170101']=historical_prod_rw.loc[2017, 'Concentrate production']\n",
    "conc_prod_series.loc['20170101'] = conc_prod_series_cn.loc['20170101'] + conc_prod_series_rw.loc['20170101']\n",
    "\n",
    "# Initialize refined supply and demand\n",
    "ref_prod_series=pd.Series(0, index=simulation_time)\n",
    "ref_prod_series_cn=pd.Series(0, index=simulation_time)\n",
    "ref_prod_series_rw=pd.Series(0, index=simulation_time)\n",
    "ref_demand_series=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "ref_demand_series_cn=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "ref_demand_series_rw=pd.Series(0, index=pd.date_range('20170101', simulation_end_time, freq='AS'))\n",
    "ref_demand_series_cn.loc['20170101']=historical_prod_cn.loc[2017, 'Refined usage']# - historical_ref_imports_cn.loc[2017]\n",
    "ref_demand_series_rw.loc['20170101']=historical_prod_rw.loc[2017, 'Refined usage']# + historical_ref_imports_cn.loc[2017]\n",
    "ref_demand_series.loc['20170101'] = ref_demand_series_cn.loc['20170101'] + ref_demand_series_rw.loc['20170101']\n",
    "\n",
    "# Initialize end use by product stats\n",
    "use_product_future=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=use_product_history.columns)\n",
    "use_product_all_life=pd.concat([use_product_history, use_product_future])\n",
    "use_product_future_cn=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=use_product_history_cn.columns)\n",
    "use_product_all_life_cn=pd.concat([use_product_history_cn, use_product_future_cn])\n",
    "use_product_future_rw=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=use_product_history_rw.columns)\n",
    "use_product_all_life_rw=pd.concat([use_product_history_rw, use_product_future_rw])\n",
    "\n",
    "# Initialize old scrap history\n",
    "product_eol_history_cn=product_reach_eol(use_product_history_cn, product_lifetime_freq_df_cn)\n",
    "product_eol_history_rw=product_reach_eol(use_product_history_rw, product_lifetime_freq_df)\n",
    "product_eol_history=product_eol_history_cn + product_eol_history_rw\n",
    "\n",
    "# Old scrap available \n",
    "old_scrap_available_history_cn = old_scrap_gen_init(product_eol_history_cn, product_to_waste_collectable, product_to_cathode_alloy,\n",
    "                                    collect_rate_cn, sort_eff_cn, prod_spec.copy(), s2s)\n",
    "old_scrap_available_history_rw = old_scrap_gen_init(product_eol_history_rw, product_to_waste_collectable, product_to_cathode_alloy,\n",
    "                                    collect_rate, sort_eff, prod_spec.copy(), s2s)\n",
    "old_scrap_available_history = old_scrap_available_history_cn + old_scrap_available_history_rw\n",
    "\n",
    "old_scrap_available_future=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=old_scrap_available_history.columns)\n",
    "old_scrap_available_future_cn=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=old_scrap_available_history_cn.columns)\n",
    "old_scrap_available_future_rw=pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns=old_scrap_available_history_rw.columns)\n",
    "old_scrap_available_cn = pd.concat([old_scrap_available_history_cn, old_scrap_available_future_cn])\n",
    "old_scrap_available_rw = pd.concat([old_scrap_available_history_rw, old_scrap_available_future_rw])\n",
    "old_scrap_available = pd.concat([old_scrap_available_history, old_scrap_available_future])\n",
    "\n",
    "# Initialize direct melt demand\n",
    "direct_melt_sectorial_demand_cn=(use_product_all_life_cn*product_to_cathode_alloy.loc[:, 'Alloyed'])\n",
    "direct_melt_sectorial_demand_rw=(use_product_all_life_rw*product_to_cathode_alloy.loc[:, 'Alloyed'])\n",
    "direct_melt_sectorial_demand = direct_melt_sectorial_demand_cn + direct_melt_sectorial_demand_rw\n",
    "\n",
    "direct_melt_sectorial_demand_cn.loc[:,'Unalloyed'] = (use_product_all_life_cn*product_to_cathode_alloy.loc[:, 'Copper']).sum(axis = 1)\n",
    "direct_melt_sectorial_demand_rw.loc[:,'Unalloyed'] = (use_product_all_life_rw*product_to_cathode_alloy.loc[:, 'Copper']).sum(axis = 1)\n",
    "direct_melt_sectorial_demand.loc[:, 'Unalloyed'] = direct_melt_sectorial_demand_cn.loc[:, 'Unalloyed'] + direct_melt_sectorial_demand_rw.loc[:, 'Unalloyed']\n",
    "# Including imports\n",
    "direct_melt_sectorial_demand_cn.loc[1960:2018, 'Unalloyed'] -= historical_ref_imports_cn.loc[1960:2018]\n",
    "direct_melt_sectorial_demand_rw.loc[1960:2018, 'Unalloyed'] += historical_ref_imports_cn.loc[1960:2018]\n",
    "\n",
    "# Initialize new scrap history\n",
    "new_scrap_available_history_cn = pd.DataFrame(0, index = product_eol_history_cn.index, columns = old_scrap_available_history_cn.columns)\n",
    "new_scrap_available_history_rw = pd.DataFrame(0, index = product_eol_history_rw.index, columns = old_scrap_available_history_rw.columns)\n",
    "new_scrap_available_history = pd.DataFrame(0, index = product_eol_history.index, columns = old_scrap_available_history.columns)\n",
    "new_scrap_alloys_cn = pd.DataFrame(0, index = product_eol_history_cn.index, columns = list(prod_spec.loc[:,'Primary code'].unique())+list(['New No.1']))\n",
    "new_scrap_alloys_rw = pd.DataFrame(0, index = product_eol_history_rw.index, columns = list(prod_spec.loc[:,'Primary code'].unique())+list(['New No.1']))\n",
    "prod_spec_cop = prod_spec.copy()\n",
    "for i in prod_spec_cop.index:\n",
    "    prod_spec_cop.loc[i+prod_spec.shape[0],:] = prod_spec_cop.loc[i,:]\n",
    "    prod_spec_cop.loc[i+prod_spec.shape[0],'UNS'] = prod_spec_cop.loc[i,'UNS'] + '_rw'\n",
    "\n",
    "for year_i in new_scrap_available_history.index:\n",
    "    home_scrap_ratio=home_scrap_ratio_series.loc[year_i]\n",
    "    exchange_scrap_ratio=exchange_scrap_ratio_series.loc[year_i]\n",
    "    \n",
    "    # Initialize new scrap availability history\n",
    "    new_scrap_available_year_i_cn, new_scrap_alloys_cn_year_i = \\\n",
    "    new_scrap_gen_oneyear(use_product_history_cn.loc[year_i], product_to_waste_no_loss, product_to_cathode_alloy, \n",
    "                        collect_rate_cn, sort_eff_cn, prod_spec.copy(), s2s, new_scrap_gen_cn, exchange_scrap_ratio, \n",
    "                        home_scrap_ratio, 1)\n",
    "    new_scrap_available_year_i_rw, new_scrap_alloys_rw_year_i = \\\n",
    "    new_scrap_gen_oneyear(use_product_history_rw.loc[year_i], product_to_waste_no_loss, product_to_cathode_alloy, \n",
    "                        collect_rate, sort_eff, prod_spec.copy(), s2s, new_scrap_gen, exchange_scrap_ratio, \n",
    "                        home_scrap_ratio 2)\n",
    "    new_scrap_alloys_cn_year_i.loc[new_scrap_alloys_cn_year_i.loc[:,'Availability'] < 0,'Availability'] = 0\n",
    "    new_scrap_alloys_rw_year_i.loc[new_scrap_alloys_rw_year_i.loc[:,'Availability'] < 0,'Availability'] = 0\n",
    "        \n",
    "    new_scrap_available_history_cn.loc[year_i] = new_scrap_available_year_i_cn\n",
    "    new_scrap_available_history_rw.loc[year_i] = new_scrap_available_year_i_rw\n",
    "    new_scrap_available_history.loc[year_i] = new_scrap_available_year_i_cn + new_scrap_available_year_i_rw\n",
    "    new_scrap_alloys_cn.loc[year_i] = new_scrap_alloys_cn_year_i.loc[:,'Availability']\n",
    "    new_scrap_alloys_rw.loc[year_i] = new_scrap_alloys_rw_year_i.loc[:,'Availability']\n",
    "\n",
    "new_scrap_alloys_compositions = new_scrap_alloys_cn_year_i.loc[:,:'Low_Fe']\n",
    "\n",
    "new_scrap_available_future_cn = pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns = new_scrap_available_history_cn.columns)\n",
    "new_scrap_available_future_rw = pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns = new_scrap_available_history_rw.columns)\n",
    "new_scrap_available_future = pd.DataFrame(0, index=np.arange(2019, 2041, 1), columns = new_scrap_available_history.columns)\n",
    "new_scrap_available_cn = pd.concat([new_scrap_available_history_cn, new_scrap_available_future_cn])\n",
    "new_scrap_available_rw = pd.concat([new_scrap_available_history_rw, new_scrap_available_future_rw])\n",
    "new_scrap_available = pd.concat([new_scrap_available_history, new_scrap_available_future])\n",
    "\n",
    "# Assumes China scrap distribution is the same as the rest of the world\n",
    "scrap_imports_cn_all = (old_scrap_available_rw.apply(lambda x: x / old_scrap_available_rw.sum(axis=1) * \\\n",
    "                        historical_prod_cn.loc[:,'Copper Scrap Imports, COMTRADE (kt)'])).loc[1960:2040]\n",
    "\n",
    "# China's future imports\n",
    "for i in scrap_imports_cn_all.loc[2019:].index:\n",
    "    scrap_imports_cn_all.loc[i, :] = scrap_imports_cn_all.loc[2018, :]\n",
    "original_scrap_imports_cn_all = scrap_imports_cn_all.copy()\n",
    "    \n",
    "# Summing to produce all available scraps\n",
    "all_scrap_available_cn = old_scrap_available_cn + new_scrap_available_cn + scrap_imports_cn_all\n",
    "all_scrap_available_rw = old_scrap_available_rw + new_scrap_available_rw - scrap_imports_cn_all\n",
    "all_scrap_available = all_scrap_available_cn + all_scrap_available_rw\n",
    "total_unalloyed_cn = all_scrap_available_cn.loc[:,'No.1':'No.2'].sum(axis = 1)\n",
    "total_unalloyed_rw = all_scrap_available_rw.loc[:,'No.1':'No.2'].sum(axis = 1)\n",
    "total_unalloyed = all_scrap_available.loc[:,'No.1':'No.2'].sum(axis = 1)\n",
    "\n",
    "# assuming historical No.1/No.2 ratio is at the 2018 value into the past\n",
    "all_scrap_available_cn.loc[:,'No.1'] = total_unalloyed_cn.loc[:] - historical_prod_cn.loc[:, 'Secondary refining production'] / scrap_to_cathode_eff * 0.85\n",
    "all_scrap_available_rw.loc[:,'No.1'] = total_unalloyed_rw.loc[:] - historical_prod_rw.loc[:, 'Secondary refining production'] / scrap_to_cathode_eff * 0.85\n",
    "all_scrap_available_cn.loc[:,'No.2'] = historical_prod_cn.loc[:, 'Secondary refining production'] / scrap_to_cathode_eff * 0.85\n",
    "all_scrap_available_rw.loc[:,'No.2'] = historical_prod_rw.loc[:, 'Secondary refining production'] / scrap_to_cathode_eff * 0.85\n",
    "all_scrap_available.loc[:, 'No.1'] = all_scrap_available_cn.loc[:, 'No.1'] + all_scrap_available_rw.loc[:, 'No.1']\n",
    "all_scrap_available.loc[:, 'No.2'] = all_scrap_available_cn.loc[:, 'No.2'] + all_scrap_available_rw.loc[:, 'No.2']\n",
    "\n",
    "all_scrap_available_no_accumulation = all_scrap_available.copy() \n",
    "all_scrap_available_no_accumulation_cn = all_scrap_available_cn.copy() \n",
    "all_scrap_available_no_accumulation_rw = all_scrap_available_rw.copy() \n",
    "\n",
    "# Removing new scrap that is now in alloy form\n",
    "all_scrap_available_cn.loc[1961:,'Al_Bronze':] -= alloy_to_scrap(new_scrap_alloys_cn, new_scrap_alloys_compositions).loc[1961:]\n",
    "all_scrap_available_rw.loc[1961:,'Al_Bronze':] -= alloy_to_scrap(new_scrap_alloys_rw, new_scrap_alloys_compositions).loc[1961:]\n",
    "all_scrap_available = all_scrap_available_cn + all_scrap_available_rw\n",
    "all_scrap_available_no_accumulation_cn.loc[1961:,'Al_Bronze':] -= alloy_to_scrap(new_scrap_alloys_cn, new_scrap_alloys_compositions).loc[1961:]\n",
    "all_scrap_available_no_accumulation_rw.loc[1961:,'Al_Bronze':] -= alloy_to_scrap(new_scrap_alloys_rw, new_scrap_alloys_compositions).loc[1961:]\n",
    "all_scrap_available_no_accumulation = all_scrap_available_cn + all_scrap_available_rw\n",
    "\n",
    "\n",
    "# Initialize scrap demand\n",
    "direct_melt_demand = pd.DataFrame(0, index = np.arange(1960,2041), columns = list(raw_price.columns) + list(new_scrap_alloys_compositions.index))\n",
    "direct_melt_demand_cn = pd.DataFrame(0, index = np.arange(1960,2041), columns = list(raw_price.columns) + list(new_scrap_alloys_compositions.index))\n",
    "direct_melt_demand_rw = pd.DataFrame(0, index = np.arange(1960,2041), columns = list(raw_price.columns) + list(new_scrap_alloys_compositions.index))\n",
    "\n",
    "refined_scrap_demand_cn=historical_prod_cn.loc[:, 'Secondary refining production'].div(scrap_to_cathode_eff)\n",
    "refined_scrap_demand_rw=historical_prod_rw.loc[:, 'Secondary refining production'].div(scrap_to_cathode_eff)\n",
    "refined_scrap_demand = refined_scrap_demand_cn + refined_scrap_demand_rw\n",
    "sec_ref_scrap_demand = direct_melt_demand.copy() # records scraps used in secondary refining\n",
    "sec_ref_scrap_demand_cn = direct_melt_demand.copy()\n",
    "sec_ref_scrap_demand_rw = direct_melt_demand.copy()\n",
    "\n",
    "# Blending to determine demand in the direct melt sector\n",
    "for year_i in np.arange(1960,2019):\n",
    "    if year_i > 1960:\n",
    "        all_scrap_available_cn.loc[year_i,'Al_Bronze':] += alloy_to_scrap_1yr(new_scrap_alloys_cn.loc[year_i-1] - direct_melt_demand_cn.loc[year_i-1, new_scrap_alloys_cn.columns], new_scrap_alloys_compositions)\n",
    "        all_scrap_available_rw.loc[year_i,'Al_Bronze':] += alloy_to_scrap_1yr(new_scrap_alloys_rw.loc[year_i-1] - direct_melt_demand_rw.loc[year_i-1, new_scrap_alloys_rw.columns], new_scrap_alloys_compositions)\n",
    "        \n",
    "        all_scrap_available_cn.loc[year_i,:] += all_scrap_available_cn.loc[year_i-1,:] - direct_melt_demand_cn.loc[year_i-1,:]\n",
    "        all_scrap_available_rw.loc[year_i,:] += all_scrap_available_rw.loc[year_i-1,:] - direct_melt_demand_rw.loc[year_i-1,:]\n",
    "        all_scrap_available.loc[year_i,:] = all_scrap_available_cn.loc[year_i,:] + all_scrap_available_rw.loc[year_i,:] \n",
    "    \n",
    "    new_scrap_alloys_cn_year_i = new_scrap_alloys_compositions.copy().loc[:,'High_Cu':]\n",
    "    new_scrap_alloys_cn_year_i.loc[:,'Availability'] = new_scrap_alloys_cn.loc[year_i]\n",
    "    new_scrap_alloys_rw_year_i = new_scrap_alloys_compositions.copy().loc[:,'High_Cu':]\n",
    "    new_scrap_alloys_rw_year_i.loc[:,'Availability'] = new_scrap_alloys_rw.loc[year_i]\n",
    "    \n",
    "    all_scrap_available_year_i = all_scrap_available.loc[year_i]\n",
    "    all_scrap_available_year_i_cn = all_scrap_available_cn.loc[year_i]\n",
    "    all_scrap_available_year_i_rw = all_scrap_available_rw.loc[year_i]\n",
    "\n",
    "    if year_i < 1973: #needed to limit PIR consumption to allow scrap buildup and ensure model solution\n",
    "        pir_price = 1.09\n",
    "    else:\n",
    "        pir_price = pir_price_set\n",
    "    \n",
    "    direct_melt_demand_cn.loc[year_i,:], direct_melt_demand_rw.loc[year_i,:], sec_ref_scrap_demand_cn.loc[year_i,:], sec_ref_scrap_demand_rw.loc[year_i,:],  = \\\n",
    "        blend_import_ban(all_scrap_available_year_i_cn, all_scrap_available_year_i_rw,\n",
    "                        direct_melt_sectorial_demand_cn.loc[year_i], direct_melt_sectorial_demand_rw.loc[year_i],\n",
    "                        raw_price_cn.loc[year_i], raw_price_rw.loc[year_i], s2s, prod_spec.copy(), raw_spec, \n",
    "                        refined_scrap_demand_cn.loc[year_i], refined_scrap_demand_rw.loc[year_i],\n",
    "                        historical_prod_cn.loc[year_i,'Refined usage'], historical_prod_rw.loc[year_i,'Refined usage'],\n",
    "                        fraction_yellows,\n",
    "                        new_scrap_alloys_cn_year_i, new_scrap_alloys_rw_year_i, pir_price = pir_price)\n",
    "    sec_ref_scrap_demand.loc[year_i,:] = sec_ref_scrap_demand_cn.loc[year_i,:] + sec_ref_scrap_demand_rw.loc[year_i,:]\n",
    "    direct_melt_demand.loc[year_i, :] = direct_melt_demand_cn.loc[year_i, :] + direct_melt_demand_rw.loc[year_i, :] \n",
    "    \n",
    "    if year_i % 5 == 0:\n",
    "        print(year_i)\n",
    "\n",
    "    \n",
    "\n",
    "total_scrap_demand_all_life=pd.DataFrame({'Direct melt scrap': direct_melt_demand.loc[:, scrap_subset].sum(axis=1) - refined_scrap_demand, \\\n",
    "                                        'Refined scrap': refined_scrap_demand})\n",
    "total_scrap_demand_all_life_cn=pd.DataFrame({'Direct melt scrap': direct_melt_demand_cn.loc[:, scrap_subset].sum(axis=1) - refined_scrap_demand_cn, \\\n",
    "                                            'Refined scrap': refined_scrap_demand_cn})\n",
    "total_scrap_demand_all_life_rw=pd.DataFrame({'Direct melt scrap': direct_melt_demand_rw.loc[:, scrap_subset].sum(axis=1) - refined_scrap_demand_rw, \\\n",
    "                                            'Refined scrap': refined_scrap_demand_rw})\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store new_scrap_available\n",
    "%store new_scrap_available_cn\n",
    "%store new_scrap_available_rw\n",
    "\n",
    "%store new_scrap_alloys_cn\n",
    "%store new_scrap_alloys_rw\n",
    "\n",
    "%store new_scrap_alloys_compositions\n",
    "\n",
    "%store scrap_imports_cn_all\n",
    "%store original_scrap_imports_cn_all\n",
    "\n",
    "%store historical_ref_imports_cn\n",
    "%store original_historical_ref_imports_cn\n",
    "\n",
    "%store all_scrap_available\n",
    "%store all_scrap_available_cn\n",
    "%store all_scrap_available_rw\n",
    "\n",
    "%store total_unalloyed\n",
    "\n",
    "%store all_scrap_available_no_accumulation\n",
    "%store all_scrap_available_no_accumulation_cn\n",
    "%store all_scrap_available_no_accumulation_rw\n",
    "\n",
    "%store direct_melt_sectorial_demand\n",
    "%store direct_melt_sectorial_demand_cn\n",
    "%store direct_melt_sectorial_demand_rw\n",
    "\n",
    "%store refined_scrap_demand\n",
    "%store refined_scrap_demand_cn\n",
    "%store refined_scrap_demand_rw\n",
    "\n",
    "%store direct_melt_demand\n",
    "%store direct_melt_demand_cn\n",
    "%store direct_melt_demand_rw\n",
    "\n",
    "%store sec_ref_scrap_demand\n",
    "%store sec_ref_scrap_demand_cn\n",
    "%store sec_ref_scrap_demand_rw\n",
    "\n",
    "%store raw_price\n",
    "%store raw_price_cn\n",
    "%store raw_price_rw\n",
    "\n",
    "%store total_scrap_demand_all_life\n",
    "%store total_scrap_demand_all_life_cn\n",
    "%store total_scrap_demand_all_life_rw\n",
    "\n",
    "%store scrap_use_avail_ratio\n",
    "%store scrap_use_avail_ratio_cn\n",
    "%store scrap_use_avail_ratio_rw\n",
    "\n",
    "%store historical_ref_imports_cn\n",
    "%store scrap_imports_cn_all\n",
    "\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Scenario Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T18:04:03.420861Z",
     "start_time": "2021-01-27T18:02:51.431365Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scenarios = ['test']\n",
    "\n",
    "for scenario in np.arange(0,len(scenarios)):\n",
    "    print('___________________________________________________________________\\nNEW SCENARIO:', scenarios[scenario], '('+str(scenario)+'/'+str(len(scenarios))+')')\n",
    "    system_initialization()\n",
    "    %store -r\n",
    "    \n",
    "    # Spread difference multiplier\n",
    "    if 'sdiff' in scenarios[scenario]:\n",
    "        spread_diff_multiplier = float(scenarios[scenario].split()[1])\n",
    "    \n",
    "    \n",
    "    # Defining scenarios for refined import sensitivities\n",
    "    for i in np.arange(2019,2041):\n",
    "        historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018]\n",
    "        if ' inc' in scenarios[scenario] or '_200' in scenarios[scenario].split()[-1]:\n",
    "            if  '200' in scenarios[scenario]:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] + (i-2018)*200\n",
    "            else:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] + (i-2018)*100\n",
    "        elif ' dec' in scenarios[scenario]:\n",
    "            if '200' in scenarios[scenario]:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] - (i-2018)*200\n",
    "            else:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] - (i-2018)*100\n",
    "    historical_ref_imports_cn.loc[historical_ref_imports_cn<0] = 0\n",
    "\n",
    "    \n",
    "    print(str(datetime.now()))\n",
    "    mine_life_stats_panel_operating=mine_life_stats_panel_init(simulation_time, operating_mine_pool)\n",
    "    mine_pool_new_last=pd.DataFrame()\n",
    "    mine_life_stats_panel_new_last=pd.DataFrame()\n",
    "    volume_prediction_base=pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='All sectors', index_col=0, header=[0,1])\n",
    "\n",
    "    for year_i in np.arange(2018, 2041):\n",
    "\n",
    "        print('  ', year_i, scenarios[scenario])\n",
    "        t=pd.datetime(year_i, 1, 1)\n",
    "        t_lag_1=pd.datetime(year_i-1, 1, 1)\n",
    "        t_lag_2=pd.datetime(year_i-2, 1, 1)\n",
    "\n",
    "        #### Scenario parameters ####\n",
    "        sort_eff=sort_eff_series.loc[year_i]\n",
    "        collect_rate=collect_rate_series.loc[year_i]\n",
    "        sort_eff_cn=sort_eff_series_cn.loc[year_i]\n",
    "        collect_rate_cn=collect_rate_series_cn.loc[year_i]\n",
    "\n",
    "        #### Price formation ####\n",
    "        if year_i > 2018:        \n",
    "            ### Cathode price ###\n",
    "            cathode_bal_l1.loc[year_i]=ref_prod_series.loc[t_lag_1]-ref_demand_series.loc[t_lag_1]\n",
    "            print('\\tref prod: ', ref_prod_series.loc[t_lag_1], ' ref demand: ', ref_demand_series.loc[t_lag_1])\n",
    "            cathode_price_series.loc[t]=cathode_price_predict(cathode_price_series.loc[t_lag_1], \n",
    "                                                              cathode_balance=cathode_bal_l1.loc[year_i], cathode_sd_elas=cathode_sd_elas)\n",
    "\n",
    "            ### TCRC ###\n",
    "            conc_bal_l1.loc[year_i]=conc_prod_series.loc[t_lag_1]-ref_stats.loc[t_lag_1, 'Primary production']/conc_to_cathode_eff\n",
    "            tcrc_series.loc[t]=tcrc_predict(tcrc_series.loc[t_lag_1], \\\n",
    "                                            conc_balance=conc_bal_l1.loc[year_i], conc_sd_elas=conc_sd_elas)\n",
    "            tcrc_series_cn.loc[t] = tcrc_series.copy().loc[t]\n",
    "            tcrc_series_rw.loc[t] = tcrc_series.copy().loc[t]\n",
    "            \n",
    "            # Testing TCRC sensitivities, only need to uncomment for those sensitivity tests\n",
    "#             if tcrc_multiplier_cn != 0 and year_i <= tcrc_years+2018:\n",
    "#                 if 'cn' in scenarios[scenario].split()[1]:\n",
    "#                     tcrc_series_cn.loc[t] *= tcrc_multiplier_cn\n",
    "#                 if 'rw' in scenarios[scenario].split()[1]:\n",
    "#                     tcrc_series_rw.loc[t] *= tcrc_multiplier_rw\n",
    "#                 print('\\t\\tCN TCRC:', tcrc_series_cn.loc[t], 'Global TCRC:', tcrc_series.loc[t])\n",
    "            \n",
    "            ### Scrap balances\n",
    "            print('Scrap balance correction factor:', scrap_bal_correction)\n",
    "            scrap_bal_l1.loc[year_i] = all_scrap_available_no_accumulation.loc[year_i-1, scrap_subset].sum() - total_scrap_demand_all_life.loc[year_i-1].sum() / scrap_bal_correction\n",
    "            scrap_bal_l1_cn.loc[year_i] = all_scrap_available_no_accumulation_cn.loc[year_i-1, scrap_subset].sum() - total_scrap_demand_all_life_cn.loc[year_i-1].sum() / scrap_bal_correction\n",
    "            scrap_bal_l1_rw.loc[year_i] = all_scrap_available_no_accumulation_rw.loc[year_i-1, scrap_subset].sum() - total_scrap_demand_all_life_rw.loc[year_i-1].sum() / scrap_bal_correction\n",
    "            \n",
    "            cathode_price_diff=cathode_price_series.loc[t]-cathode_price_series.loc[t_lag_1]\n",
    "            # sp1 is No.1 scrap spread, sp2 is No.2 scrap spread, spa is alloyed scrap spread\n",
    "            sp2_series.loc[t]=sp2_predict(sp2_series.loc[t_lag_1], \\\n",
    "                                          scrap_balance=scrap_bal_l1.loc[year_i], scrap_sd_elas=sp2_sd_elas, \\\n",
    "                                          cathode_diff=cathode_price_diff, cathode_sp2_elas=cathode_sp2_elas)\n",
    "            sp2_series_cn.loc[t]=sp2_predict(sp2_series_cn.loc[t_lag_1], \\\n",
    "                                          scrap_balance=scrap_bal_l1_cn.loc[year_i], scrap_sd_elas=sp2_sd_elas_cn, \\\n",
    "                                          cathode_diff=cathode_price_diff, cathode_sp2_elas=cathode_sp2_elas)\n",
    "            sp2_series_rw.loc[t]=sp2_predict(sp2_series_rw.loc[t_lag_1], \\\n",
    "                                          scrap_balance=scrap_bal_l1_rw.loc[year_i], scrap_sd_elas=sp2_sd_elas_rw,\\\n",
    "                                          cathode_diff=cathode_price_diff, cathode_sp2_elas=cathode_sp2_elas)\n",
    "            sp1_series.loc[t]=sp1_predict(sp1_series.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1.loc[year_i], scrap_sd_elas=sp1_sd_elas,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_sp1_elas=cathode_sp1_elas)\n",
    "            sp1_series_cn.loc[t]=sp1_predict(sp1_series_cn.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1_cn.loc[year_i], scrap_sd_elas=sp1_sd_elas_cn,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_sp1_elas=cathode_sp1_elas)\n",
    "            sp1_series_rw.loc[t]=sp1_predict(sp1_series_rw.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1_rw.loc[year_i], scrap_sd_elas=sp1_sd_elas_rw,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_sp1_elas=cathode_sp1_elas)\n",
    "            spa_series.loc[t]=alloy_predict(spa_series.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1.loc[year_i], scrap_sd_elas=alloyed_sd_elas,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_alloy_elas=cathode_alloyed_elas)\n",
    "            spa_series_cn.loc[t]=alloy_predict(spa_series_cn.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1_cn.loc[year_i], scrap_sd_elas=alloyed_sd_elas_cn,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_alloy_elas=cathode_alloyed_elas)\n",
    "            spa_series_rw.loc[t]=alloy_predict(spa_series_rw.loc[t_lag_1],\\\n",
    "                                         scrap_balance=scrap_bal_l1_rw.loc[year_i], scrap_sd_elas=alloyed_sd_elas_cn,\\\n",
    "                                         cathode_diff=cathode_price_diff, cathode_alloy_elas=cathode_alloyed_elas)\n",
    "            if 'sdiff' in scenarios[scenario]:\n",
    "                print('\\t\\tBefore spread difference multiplier:', spread_diff_multiplier, 'CN:', round(sp2_series_cn.loc[t],2), 'RoW:', round(sp2_series_rw.loc[t],2), 'Global:', round(sp2_series.loc[t],2))\n",
    "                sp2_series_cn.loc[t] = sp2_series.loc[t] - (sp2_series.loc[t] - sp2_series_cn.loc[t])*spread_diff_multiplier\n",
    "                sp1_series_cn.loc[t] = sp1_series.loc[t] - (sp1_series.loc[t] - sp1_series_cn.loc[t])*spread_diff_multiplier\n",
    "                spa_series_cn.loc[t] = spa_series.loc[t] - (spa_series.loc[t] - spa_series_cn.loc[t])*spread_diff_multiplier\n",
    "                sp2_series_rw.loc[t] = sp2_series.loc[t] - (sp2_series.loc[t] - sp2_series_rw.loc[t])*spread_diff_multiplier\n",
    "                sp1_series_rw.loc[t] = sp1_series.loc[t] - (sp1_series.loc[t] - sp1_series_rw.loc[t])*spread_diff_multiplier\n",
    "                spa_series_rw.loc[t] = spa_series.loc[t] - (spa_series.loc[t] - spa_series_rw.loc[t])*spread_diff_multiplier\n",
    "                print('\\t\\tAfter spread difference multiplier:', spread_diff_multiplier, 'CN:', round(sp2_series_cn.loc[t],2), 'RoW:', round(sp2_series_rw.loc[t],2), 'Global:', round(sp2_series.loc[t],2))\n",
    "                \n",
    "            raw_price.loc[year_i, 'Ref_Cu'] = cathode_price_series.loc[t]\n",
    "            raw_price_cn.loc[year_i, 'Ref_Cu'] = cathode_price_series.loc[t]\n",
    "            raw_price_rw.loc[year_i, 'Ref_Cu'] = cathode_price_series.loc[t]\n",
    "            raw_price.loc[year_i, 'No.1'] = cathode_price_series.loc[t] - sp1_series.loc[t]\n",
    "            raw_price_cn.loc[year_i, 'No.1'] = cathode_price_series.loc[t] - sp1_series_cn.loc[t]\n",
    "            raw_price_rw.loc[year_i, 'No.1'] = cathode_price_series.loc[t] - sp1_series_rw.loc[t]\n",
    "            raw_price.loc[year_i, 'No.2'] = cathode_price_series.loc[t] - sp2_series.loc[t]\n",
    "            raw_price_cn.loc[year_i, 'No.2'] = cathode_price_series.loc[t] - sp2_series_cn.loc[t]\n",
    "            raw_price_rw.loc[year_i, 'No.2'] = cathode_price_series.loc[t] - sp2_series_rw.loc[t]\n",
    "            raw_price.loc[year_i, list(spa_series.columns)] = spa_series.loc[t].apply(lambda x: cathode_price_series.loc[t] - x)\n",
    "            raw_price_cn.loc[year_i, list(spa_series.columns)] = spa_series_cn.loc[t].apply(lambda x: cathode_price_series.loc[t] - x)\n",
    "            raw_price_rw.loc[year_i, list(spa_series.columns)] = spa_series_rw.loc[t].apply(lambda x: cathode_price_series.loc[t] - x)\n",
    "\n",
    "            ### Refined (non-Cu) Metal Prices ### assumes they change proportionally to copper price\n",
    "            raw_price.loc[year_i,ref_metals] = raw_price.loc[year_i-1,ref_metals].apply(lambda x: x * cathode_price_series[t] / cathode_price_series[t_lag_1])\n",
    "            raw_price_cn.loc[year_i,ref_metals] = raw_price_cn.loc[year_i-1,ref_metals].apply(lambda x: x * cathode_price_series[t] / cathode_price_series[t_lag_1])\n",
    "            raw_price_rw.loc[year_i,ref_metals] = raw_price_rw.loc[year_i-1,ref_metals].apply(lambda x: x * cathode_price_series[t] / cathode_price_series[t_lag_1])\n",
    "            \n",
    "\n",
    "        # TCRC to cents per pound\n",
    "        tcrc_cpp_series = tcrc_series.copy().div(22.0462)\n",
    "\n",
    "\n",
    "        #### Production of operating mine ####\n",
    "        for mine_id in operating_mine_pool.index:\n",
    "            mine_data = operating_mine_pool.loc[mine_id]\n",
    "            mine_life_stats = simulate_mine_life_stats_panel(simulation_time, year_i, 2018, \\\n",
    "                                                             mine_life_stats_panel_operating, mine_data, \\\n",
    "                                                             cathode_price_series, tcrc_cpp_series, \\\n",
    "                                                             pri_hyper_param, \\\n",
    "                                                             mine_cu_pct_change=mine_cu_pct_change.loc[year_i])\n",
    "            mine_life_stats_panel_operating.loc[:, idx[mine_id, :]]=mine_life_stats.loc[simulation_time, :].values\n",
    "\n",
    "        # Total production statistics\n",
    "        prod_operating=mine_life_stats_panel_operating.loc[:, idx[:, 'Recovered metal production (kt)']].sum(axis=1)\n",
    "        sxew_operating=mine_life_stats_panel_operating.loc[:, idx[sxew_id_operating, 'Recovered metal production (kt)']].sum(axis=1)\n",
    "        conc_operating=prod_operating-sxew_operating\n",
    "        print('\\tMines closing this year:', (mine_life_stats_panel_operating.loc[t,idx[:,'Ramp flag']] == 'Reclaim').sum())\n",
    "\n",
    "\n",
    "        #### Production of new mines ####\n",
    "        if year_i > 2018:\n",
    "            # Read subsample size parameter and generate new incentive pool for year_i\n",
    "            subsample_size=open_parameter.loc[year_i, 'Subsample size']\n",
    "            mine_pool_new_year_i=new_mine_data(year_i, simulation_end_time, incentive_pool, cathode_price_series, tcrc_cpp_series,\\\n",
    "                                               pri_hyper_param, subsample_size, irr_cutoff=0.15)\n",
    "            print('\\tNew mines opening this year: ', mine_pool_new_year_i.shape[0])\n",
    "\n",
    "            # Initialize mine life panel data for incentive pool year_i\n",
    "            mine_life_stats_panel_new_year_i=mine_life_stats_panel_init(simulation_time, mine_pool_new_year_i)\n",
    "\n",
    "            # Append new incentive pool at year_i\n",
    "            mine_pool_new=pd.concat([mine_pool_new_last, mine_pool_new_year_i])\n",
    "            mine_life_stats_panel_new=pd.concat([mine_life_stats_panel_new_last, mine_life_stats_panel_new_year_i], axis=1)\n",
    "\n",
    "            for mine_id in mine_pool_new.index:\n",
    "                mine_data = mine_pool_new.loc[mine_id]\n",
    "                mine_life_stats = simulate_mine_life_stats_panel(simulation_time, year_i, mine_data.loc['Initial year'], \n",
    "                                                                 mine_life_stats_panel_new, mine_data, \n",
    "                                                                 cathode_price_series, tcrc_cpp_series, pri_hyper_param,\n",
    "                                                                 mine_cu_pct_change=mine_cu_pct_change.loc[year_i])\n",
    "                mine_life_stats_panel_new.loc[:, idx[mine_id, :]]=mine_life_stats.loc[simulation_time, :].values\n",
    "\n",
    "\n",
    "            # Total production statistics\n",
    "            prod_new=mine_life_stats_panel_new.loc[:, idx[:, 'Recovered metal production (kt)']].sum(axis=1)\n",
    "            sxew_new=mine_life_stats_panel_new.loc[:, idx[sxew_id_new, 'Recovered metal production (kt)']].sum(axis=1)\n",
    "            conc_new=prod_new-sxew_new\n",
    "\n",
    "            # Update incentive pool info\n",
    "            mine_pool_new_last=mine_pool_new.copy()\n",
    "            mine_life_stats_panel_new_last=mine_life_stats_panel_new.copy()\n",
    "\n",
    "\n",
    "        #### Update total mining production ####\n",
    "        if year_i == 2018:\n",
    "            conc_new=pd.Series(0, index=simulation_time)\n",
    "            prod_new=pd.Series(0, index=simulation_time)\n",
    "\n",
    "        conc_prod_series.loc[t]=conc_operating.loc[t]+conc_new.loc[t]\n",
    "        sxew_all.loc[t]=sxew_operating.loc[t]+sxew_new.loc[t]\n",
    "        print('\\tTotal mining production: ', prod_operating.loc[t]+prod_new.loc[t])\n",
    "\n",
    "\n",
    "        #### Demand for refined copper ####\n",
    "        if year_i == 2018:\n",
    "            pass\n",
    "        else:    \n",
    "            intensity_next=intensity_prediction_one_year(year_i, cathode_price_series, gdp_growth_prediction_base, \\\n",
    "                                                         intensity_prediction.loc[year_i-1, :], volume_prediction_base, \\\n",
    "                                                         elas_sec_reg, method='sec and reg')\n",
    "            intensity_prediction.loc[year_i, :]=intensity_next.values\n",
    "            demand_prediction.loc[year_i, :]=intensity_prediction.loc[year_i, :].mul(volume_prediction_base.loc[year_i, :]).values\n",
    "\n",
    "        # Demand by shape and refined copper demand - beginning of China separation\n",
    "        demand_by_sector_cn = demand_prediction.loc[:,idx[:,'China']].groupby(level=0,axis=1).sum()\n",
    "        demand_by_sector_rw = demand_prediction.groupby(level=0,axis=1).sum() - demand_prediction.loc[:,idx[:,'China']].groupby(level=0,axis=1).sum()\n",
    "        demand_by_sector = demand_prediction.groupby(level=0,axis=1).sum()\n",
    "        \n",
    "        if year_i > 2018:\n",
    "            ref_demand_series.loc[t_lag_1]=direct_melt_demand.loc[year_i-1, 'Ref_Cu']\n",
    "            ref_demand_series_cn.loc[t_lag_1]=direct_melt_demand_cn.loc[year_i-1, 'Ref_Cu'] \n",
    "            ref_demand_series_rw.loc[t_lag_1]=direct_melt_demand_rw.loc[year_i-1, 'Ref_Cu']\n",
    "            ref_demand_series.loc[t_lag_1] = ref_demand_series_cn.loc[t_lag_1] + ref_demand_series_rw.loc[t_lag_1]\n",
    "        \n",
    "        #### Production of refineries ####\n",
    "        if year_i == 2018:\n",
    "            pass\n",
    "        else:\n",
    "            ref_bal_l1.loc[year_i] = ref_prod_series.loc[t_lag_1]/ref_demand_series.loc[t_lag_1]\n",
    "            ref_bal_l1_cn.loc[year_i] = ref_prod_series_cn.loc[t_lag_1]/ref_demand_series_cn.loc[t_lag_1]\n",
    "            ref_bal_l1_rw.loc[year_i] = ref_prod_series_rw.loc[t_lag_1]/ref_demand_series_rw.loc[t_lag_1]\n",
    "            ref_stats_next_cn=simulate_refinery_production_oneyear(year_i, tcrc_series_cn, sp2_series_cn, \\\n",
    "                                                                   ref_demand_series_cn, all_scrap_available_no_accumulation_cn.sum(axis=1),\n",
    "                                                                   ref_stats_cn, ref_hyper_param_cn, growth_lag=1,\n",
    "                                                                   ref_cu_pct_change = ref_cu_pct_change.loc[year_i],\n",
    "                                                                   ref_sr_pct_change = ref_sr_pct_change.loc[year_i])        \n",
    "            ref_stats_next_rw=simulate_refinery_production_oneyear(year_i, tcrc_series_rw, sp2_series_rw, \n",
    "                                                                   ref_demand_series_rw, all_scrap_available_no_accumulation_rw.sum(axis=1),\n",
    "                                                                   ref_stats_rw, ref_hyper_param_rw, growth_lag=1, \n",
    "                                                                   ref_cu_pct_change = ref_cu_pct_change.loc[year_i],\n",
    "                                                                   ref_sr_pct_change = ref_sr_pct_change.loc[year_i])\n",
    "            ref_stats_cn.loc[t, :]=ref_stats_next_cn\n",
    "            ref_stats_rw.loc[t, :]=ref_stats_next_rw\n",
    "            ref_stats.loc[t,['Primary capacity', 'Secondary capacity', 'Primary production', 'Secondary production']] = \\\n",
    "               ref_stats_next_cn.loc[['Primary capacity', 'Secondary capacity', 'Primary production', 'Secondary production']] \\\n",
    "               + ref_stats_next_rw.loc[['Primary capacity', 'Secondary capacity', 'Primary production', 'Secondary production']]\n",
    "\n",
    "        total_ref_prod_cn=ref_stats_cn.loc[t, 'Primary production']+ref_stats_cn.loc[t, 'Secondary production']\n",
    "        total_ref_prod_rw=ref_stats_rw.loc[t, 'Primary production']+ref_stats_rw.loc[t, 'Secondary production']+sxew_all.loc[t]\n",
    "        total_ref_prod = total_ref_prod_cn + total_ref_prod_rw\n",
    "        ref_prod_series_cn.loc[t]=total_ref_prod_cn\n",
    "        ref_prod_series_rw.loc[t]=total_ref_prod_rw\n",
    "        ref_prod_series.loc[t] = total_ref_prod_cn + total_ref_prod_rw\n",
    "\n",
    "\n",
    "        #### Generation of old scrap ####\n",
    "        if year_i > 2018:\n",
    "            # Calculate end use by sector and by product\n",
    "            use_sector_year_i_cn=demand_by_sector_cn.loc[year_i]\n",
    "            use_sector_year_i_rw=demand_by_sector_rw.loc[year_i]\n",
    "            use_product_year_i_cn=pd.Series(np.matmul(use_sector_year_i_cn, sector_to_product.transpose()), \\\n",
    "                                             index=sector_to_product.index)\n",
    "            use_product_year_i_rw=pd.Series(np.matmul(use_sector_year_i_rw, sector_to_product.transpose()), \\\n",
    "                                            index=sector_to_product.index)\n",
    "            use_product_all_life_cn.loc[year_i]=use_product_year_i_cn.values\n",
    "            use_product_all_life_rw.loc[year_i]=use_product_year_i_rw.values\n",
    "            use_product_all_life.loc[year_i]=use_product_year_i_cn.values + use_product_year_i_rw.values\n",
    "\n",
    "\n",
    "            # Product reaching end of life and waste collected\n",
    "            product_eol_year_i_cn = product_reach_eol_oneyear(year_i, use_product_all_life_cn, product_lifetime_freq_df)\n",
    "            product_eol_year_i_rw = product_reach_eol_oneyear(year_i, use_product_all_life_rw, product_lifetime_freq_df)\n",
    "            product_eol_year_i = product_eol_year_i_cn + product_eol_year_i_rw\n",
    "            \n",
    "            # Old scrap available by scrap type\n",
    "            old_scrap_available_year_i_cn = old_scrap_gen_oneyear(product_eol_year_i_cn, product_to_waste_collectable, \\\n",
    "                                                                  product_to_cathode_alloy, collect_rate_cn, sort_eff_cn, \\\n",
    "                                                                  prod_spec, s2s)\n",
    "            old_scrap_available_year_i_rw = old_scrap_gen_oneyear(product_eol_year_i_rw, product_to_waste_collectable, \\\n",
    "                                                                  product_to_cathode_alloy, collect_rate, sort_eff, \\\n",
    "                                                                  prod_spec, s2s)\n",
    "            old_scrap_available_cn.loc[year_i] = old_scrap_available_year_i_cn\n",
    "            old_scrap_available_rw.loc[year_i] = old_scrap_available_year_i_rw\n",
    "            old_scrap_available.loc[year_i] = old_scrap_available_year_i_cn + old_scrap_available_year_i_rw\n",
    "\n",
    "        # Defining this segment earlier than before\n",
    "        direct_melt_sectorial_demand_cn.loc[year_i, :'Diverse']=(use_product_all_life_cn*product_to_cathode_alloy.loc[:, 'Alloyed']).loc[year_i]\n",
    "        direct_melt_sectorial_demand_rw.loc[year_i, :'Diverse']=(use_product_all_life_rw*product_to_cathode_alloy.loc[:, 'Alloyed']).loc[year_i]\n",
    "        direct_melt_sectorial_demand.loc[year_i, :'Diverse']=direct_melt_sectorial_demand_cn.loc[year_i,:'Diverse'] + direct_melt_sectorial_demand_rw.loc[year_i,:'Diverse']\n",
    "\n",
    "        direct_melt_sectorial_demand_cn.loc[year_i,'Unalloyed'] = (use_product_all_life_cn.loc[year_i]*\\\n",
    "                                                                   product_to_cathode_alloy.loc[:, 'Copper']).sum()\\\n",
    "                                                                   - historical_ref_imports_cn.loc[year_i]\n",
    "        direct_melt_sectorial_demand_rw.loc[year_i,'Unalloyed'] = (use_product_all_life_rw.loc[year_i]*\\\n",
    "                                                                   product_to_cathode_alloy.loc[:, 'Copper']).sum() \\\n",
    "                                                                   + historical_ref_imports_cn.loc[year_i]\n",
    "        direct_melt_sectorial_demand.loc[year_i, 'Unalloyed'] = direct_melt_sectorial_demand_cn.loc[year_i,'Unalloyed'] + direct_melt_sectorial_demand_rw.loc[year_i,'Unalloyed']\n",
    "\n",
    "        #### Generation of new scrap ####\n",
    "        if year_i > 2018:\n",
    "            home_scrap_ratio=home_scrap_ratio_series.loc[year_i]\n",
    "            exchange_scrap_ratio=exchange_scrap_ratio_series.loc[year_i]\n",
    "            \n",
    "            # New scrap available by scrap type\n",
    "            new_scrap_available_year_i_cn, new_scrap_alloys_cn_year_i = \\\n",
    "                new_scrap_gen_oneyear(use_product_all_life_cn.loc[year_i], product_to_waste_no_loss, product_to_cathode_alloy, \\\n",
    "                                  collect_rate_cn, sort_eff_cn, prod_spec.copy(), s2s, new_scrap_gen_cn, exchange_scrap_ratio, \\\n",
    "                                  home_scrap_ratio)\n",
    "            new_scrap_available_year_i_rw, new_scrap_alloys_rw_year_i = \\\n",
    "                new_scrap_gen_oneyear(use_product_all_life_rw.loc[year_i], product_to_waste_no_loss, product_to_cathode_alloy, \\\n",
    "                                  collect_rate, sort_eff, prod_spec.copy(), s2s, new_scrap_gen, exchange_scrap_ratio, \\\n",
    "                                  home_scrap_ratio)\n",
    "            new_scrap_available_cn.loc[year_i] = new_scrap_available_year_i_cn\n",
    "            new_scrap_available_rw.loc[year_i] = new_scrap_available_year_i_rw\n",
    "            new_scrap_available.loc[year_i] = new_scrap_available_year_i_cn + new_scrap_available_year_i_rw\n",
    "\n",
    "            new_scrap_alloys_cn.loc[year_i] = new_scrap_alloys_cn_year_i.loc[:,'Availability']\n",
    "            new_scrap_alloys_rw.loc[year_i] = new_scrap_alloys_rw_year_i.loc[:,'Availability']\n",
    "            new_scrap_alloys_compositions = new_scrap_alloys_cn_year_i.loc[:,:'Low_Fe']\n",
    "                \n",
    "            # All scrap\n",
    "            all_scrap_available_cn.loc[year_i] = old_scrap_available_year_i_cn + new_scrap_available_year_i_cn\n",
    "            all_scrap_available_rw.loc[year_i] = old_scrap_available_year_i_rw + new_scrap_available_year_i_rw\n",
    "            all_scrap_available.loc[year_i] = all_scrap_available_cn.loc[year_i] + all_scrap_available_rw.loc[year_i]\n",
    "            all_scrap_available_cn.loc[year_i] += scrap_imports_cn_all.loc[year_i]\n",
    "            all_scrap_available_rw.loc[year_i] -= scrap_imports_cn_all.loc[year_i]\n",
    "\n",
    "        total_unalloyed_year_i_cn = all_scrap_available_cn.loc[year_i,'No.1':'No.2'].sum()\n",
    "        total_unalloyed_year_i_rw = all_scrap_available_rw.loc[year_i,'No.1':'No.2'].sum()\n",
    "        total_unalloyed_year_i = all_scrap_available.loc[year_i,'No.1':'No.2'].sum()\n",
    "\n",
    "        print('\\tTotal scrap supply, China: ', all_scrap_available_cn.sum(axis=1).loc[year_i])\n",
    "        print('\\tTotal scrap supply, RoW: ', all_scrap_available_rw.sum(axis=1).loc[year_i])\n",
    "\n",
    "        # Updating scrap availability\n",
    "        if year_i > 2018:\n",
    "            refined_scrap_demand_year_i_cn=ref_stats_cn.loc[t, 'Secondary production']/scrap_to_cathode_eff\n",
    "            all_scrap_available_cn.loc[year_i, 'No.1'] = total_unalloyed_year_i_cn - refined_scrap_demand_year_i_cn * 0.85\n",
    "            all_scrap_available_cn.loc[year_i, 'No.2'] = refined_scrap_demand_year_i_cn * 0.85\n",
    "\n",
    "            refined_scrap_demand_year_i_rw=ref_stats_rw.loc[t, 'Secondary production']/scrap_to_cathode_eff\n",
    "            all_scrap_available_rw.loc[year_i, 'No.1'] = total_unalloyed_year_i_rw - refined_scrap_demand_year_i_rw * 0.85\n",
    "            all_scrap_available_rw.loc[year_i, 'No.2'] = refined_scrap_demand_year_i_rw * 0.85\n",
    "\n",
    "            refined_scrap_demand_year_i = refined_scrap_demand_year_i_cn + refined_scrap_demand_year_i_rw\n",
    "            all_scrap_available.loc[year_i, 'No.1'] = total_unalloyed_year_i - refined_scrap_demand_year_i * 0.85\n",
    "            all_scrap_available.loc[year_i, 'No.2'] = refined_scrap_demand_year_i * 0.85\n",
    "                \n",
    "\n",
    "            all_scrap_available_no_accumulation.loc[year_i] = all_scrap_available.loc[year_i].copy()\n",
    "            all_scrap_available.loc[year_i,:] += all_scrap_available.loc[year_i-1,:] - direct_melt_demand.loc[year_i-1,:]\n",
    "            all_scrap_available_no_accumulation_cn.loc[year_i] = all_scrap_available_cn.loc[year_i].copy()\n",
    "            all_scrap_available_cn.loc[year_i,:] += all_scrap_available_cn.loc[year_i-1,:] - direct_melt_demand_cn.loc[year_i-1,:]\n",
    "            all_scrap_available_no_accumulation_rw.loc[year_i] = all_scrap_available_rw.loc[year_i].copy()\n",
    "            all_scrap_available_rw.loc[year_i,:] += all_scrap_available_rw.loc[year_i-1,:] - direct_melt_demand_rw.loc[year_i-1,:]\n",
    "\n",
    "            \n",
    "            all_scrap_available_cn.loc[year_i,'Al_Bronze':] -= alloy_to_scrap_1yr(new_scrap_alloys_cn.loc[year_i], new_scrap_alloys_compositions)\n",
    "            all_scrap_available_rw.loc[year_i,'Al_Bronze':] -= alloy_to_scrap_1yr(new_scrap_alloys_rw.loc[year_i], new_scrap_alloys_compositions)\n",
    "            all_scrap_available_cn.loc[year_i,'Al_Bronze':] += alloy_to_scrap_1yr(new_scrap_alloys_cn.loc[year_i-1] - direct_melt_demand_cn.loc[year_i-1, new_scrap_alloys_cn.columns], new_scrap_alloys_compositions)\n",
    "            all_scrap_available_rw.loc[year_i,'Al_Bronze':] += alloy_to_scrap_1yr(new_scrap_alloys_rw.loc[year_i-1] - direct_melt_demand_rw.loc[year_i-1, new_scrap_alloys_rw.columns], new_scrap_alloys_compositions)\n",
    "            all_scrap_available.loc[year_i] = all_scrap_available_cn.loc[year_i] + all_scrap_available_rw.loc[year_i]\n",
    "            all_scrap_available_no_accumulation_cn.loc[year_i,'Al_Bronze':] -= alloy_to_scrap_1yr(new_scrap_alloys_cn.loc[year_i], new_scrap_alloys_compositions)\n",
    "            all_scrap_available_no_accumulation_rw.loc[year_i,'Al_Bronze':] -= alloy_to_scrap_1yr(new_scrap_alloys_rw.loc[year_i], new_scrap_alloys_compositions)\n",
    "            all_scrap_available_no_accumulation.loc[year_i] = all_scrap_available_no_accumulation_cn.loc[year_i] + all_scrap_available_no_accumulation_rw.loc[year_i]\n",
    "\n",
    "\n",
    "            new_scrap_alloys_cn_year_i = new_scrap_alloys_compositions.copy().loc[:,'High_Cu':]\n",
    "            new_scrap_alloys_cn_year_i.loc[:,'Availability'] = new_scrap_alloys_cn.loc[year_i]\n",
    "            new_scrap_alloys_rw_year_i = new_scrap_alloys_compositions.copy().loc[:,'High_Cu':]\n",
    "            new_scrap_alloys_rw_year_i.loc[:,'Availability'] = new_scrap_alloys_rw.loc[year_i]\n",
    "\n",
    "            \n",
    "            all_scrap_available_year_i_cn = all_scrap_available_cn.loc[year_i]\n",
    "            all_scrap_available_year_i_rw = all_scrap_available_rw.loc[year_i]\n",
    "        \n",
    "        # Scrap demand\n",
    "        if year_i > 2018:\n",
    "            refined_scrap_demand_year_i_cn=ref_stats_cn.loc[t, 'Secondary production']/scrap_to_cathode_eff\n",
    "            refined_scrap_demand_year_i_rw=ref_stats_rw.loc[t, 'Secondary production']/scrap_to_cathode_eff\n",
    "            refined_scrap_demand_year_i = refined_scrap_demand_year_i_cn + refined_scrap_demand_year_i_rw\n",
    "            print('\\t\\tPIR price:', pir_price, 'times refined copper price')\n",
    "            \n",
    "            direct_melt_demand_cn.loc[year_i,:], direct_melt_demand_rw.loc[year_i,:], \\\n",
    "            sec_ref_scrap_demand_cn.loc[year_i,:], sec_ref_scrap_demand_rw.loc[year_i,:] = \\\n",
    "                blend_import_ban(all_scrap_available_year_i_cn, all_scrap_available_year_i_rw,\\\n",
    "                        direct_melt_sectorial_demand_cn.loc[year_i], direct_melt_sectorial_demand_rw.loc[year_i],\\\n",
    "                        raw_price_cn.loc[year_i], raw_price_rw.loc[year_i], s2s, prod_spec.copy(), raw_spec.copy(), \\\n",
    "                        refined_scrap_demand_year_i_cn, refined_scrap_demand_year_i_rw,\\\n",
    "                        direct_melt_sectorial_demand_cn.loc[year_i,'Unalloyed'], direct_melt_sectorial_demand_rw.loc[year_i,'Unalloyed'],\\\n",
    "                        fraction_yellows,\\\n",
    "                        new_scrap_alloys_cn_year_i, new_scrap_alloys_rw_year_i, \n",
    "                        pir_price = pir_price)\n",
    "            sec_ref_scrap_demand.loc[year_i,:] = sec_ref_scrap_demand_cn.loc[year_i,:] + sec_ref_scrap_demand_rw.loc[year_i,:]\n",
    "        \n",
    "            direct_melt_demand.loc[year_i,:] = direct_melt_demand_cn.loc[year_i,:] + direct_melt_demand_rw.loc[year_i,:]\n",
    "            print('\\tTotal direct melt scrap demand, China: ', direct_melt_demand_cn.sum(axis=1).loc[year_i])\n",
    "            print('\\tTotal direct melt scrap demand, RoW: ', direct_melt_demand_rw.sum(axis=1).loc[year_i])\n",
    "            \n",
    "            total_scrap_demand_all_life_cn.loc[year_i,'Direct melt scrap'] = (direct_melt_demand_cn.loc[year_i,:] - sec_ref_scrap_demand_cn.loc[year_i, :]).loc[scrap_subset].sum() + direct_melt_demand_cn.loc[year_i,'New No.1']\n",
    "            total_scrap_demand_all_life_cn.loc[year_i,'Refined scrap'] = sec_ref_scrap_demand_cn.loc[year_i,scrap_subset].sum()\n",
    "            total_scrap_demand_all_life_rw.loc[year_i,'Direct melt scrap'] = (direct_melt_demand_rw.loc[year_i,:] - sec_ref_scrap_demand_rw.loc[year_i, :]).loc[scrap_subset].sum() + direct_melt_demand_rw.loc[year_i,'New No.1']\n",
    "            total_scrap_demand_all_life_rw.loc[year_i,'Refined scrap'] = sec_ref_scrap_demand_rw.loc[year_i,scrap_subset].sum()\n",
    "            total_scrap_demand_all_life.loc[year_i,'Direct melt scrap'] = total_scrap_demand_all_life_cn.loc[year_i,'Direct melt scrap'] + total_scrap_demand_all_life_rw.loc[year_i,'Direct melt scrap']\n",
    "            total_scrap_demand_all_life.loc[year_i,'Refined scrap'] = total_scrap_demand_all_life_cn.loc[year_i,'Refined scrap'] + total_scrap_demand_all_life_rw.loc[year_i,'Refined scrap']\n",
    "       \n",
    "        ref_demand_series_cn.loc[t]=direct_melt_demand_cn.loc[year_i, 'Ref_Cu']\n",
    "        ref_demand_series_rw.loc[t]=direct_melt_demand_rw.loc[year_i, 'Ref_Cu']\n",
    "        ref_demand_series.loc[t] = ref_demand_series_cn.loc[t] + ref_demand_series_rw.loc[t]\n",
    "        \n",
    "    print(str(datetime.now()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previously-run scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i in ['Easiest scrap import control']:\n",
    "    # Easiest scrap import control\n",
    "    import_multiplier = 1\n",
    "    if ' 50yoy' in scenarios[scenario] or '50_' in scenarios[scenario].split()[-1]:\n",
    "        import_multiplier = 0.5\n",
    "    elif ' 75yoy' in scenarios[scenario]:\n",
    "        import_multiplier = 0.75\n",
    "    elif ' 25yoy' in scenarios[scenario]:\n",
    "        import_multiplier = 0.25\n",
    "    print('Import multiplier:',import_multiplier)\n",
    "    \n",
    "    if ' baseline' in scenarios[scenario]:\n",
    "        scrap_imports_cn_all = original_scrap_imports_cn_all.copy()\n",
    "           \n",
    "    elif ' No.2 ' in scenarios[scenario] or 'n_' in scenarios[scenario].split()[-1] or 'no2' in scenarios[scenario]:\n",
    "        scrap_imports_cn_all = original_scrap_imports_cn_all.copy()\n",
    "        for i in np.arange(2019,2041):\n",
    "            scrap_imports_cn_all.loc[i,'No.2'] = scrap_imports_cn_all.loc[i-1,'No.2'] * import_multiplier\n",
    "                \n",
    "    elif ' alloyed ' in scenarios[scenario]:\n",
    "        scrap_imports_cn_all = original_scrap_imports_cn_all.copy()\n",
    "        for i in np.arange(2019,2041):\n",
    "            scrap_imports_cn_all.loc[i,'Al_Bronze':] = scrap_imports_cn_all.loc[i-1,'Al_Bronze':] * import_multiplier\n",
    "                \n",
    "    elif ' both ' in scenarios[scenario] or 'b_' in scenarios[scenario].split()[-1]:\n",
    "        scrap_imports_cn_all = original_scrap_imports_cn_all.copy()\n",
    "        for i in np.arange(2019,2041):\n",
    "            scrap_imports_cn_all.loc[i,'No.2':] = scrap_imports_cn_all.loc[i-1,'No.2':] * import_multiplier\n",
    "    else:\n",
    "        scrap_imports_cn_all = original_scrap_imports_cn_all.copy()\n",
    "    print('Scrap imports:',scrap_imports_cn_all.loc[2018:])\n",
    "\n",
    "for i in ['Defining scenarios for refined import sensitivities']:\n",
    "    for i in np.arange(2019,2041):\n",
    "        historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018]\n",
    "        if ' inc ' in scenarios[scenario]:\n",
    "            if  ' 200 ' in scenarios[scenario]:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] + (i-2018)*200\n",
    "            else:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] + (i-2018)*100\n",
    "        elif ' dec ' in scenarios[scenario]:\n",
    "            if ' 200 ' in scenarios[scenario]:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] - (i-2018)*200\n",
    "            else:\n",
    "                historical_ref_imports_cn.loc[i] = historical_ref_imports_cn.loc[2018] - (i-2018)*100\n",
    "    historical_ref_imports_cn.loc[historical_ref_imports_cn<0] = 0\n",
    "    print(historical_ref_imports_cn)\n",
    "    \n",
    "    \n",
    "\n",
    "# scrap sd elasticity sensitivities\n",
    "    scenarios = ['scrap sd elas baseline 20200527',\n",
    "                 'scrap 1.0 both 50yoy',\n",
    "                 'scrap 1.0 both 50yoy 100 inc',\n",
    "                 'scrap 1.0 both 50yoy 200 inc',\n",
    "                 'scrap 1.0 both 50yoy 100 dec',\n",
    "                 'scrap 1.0 both 50yoy 200 dec',\n",
    "                 'scrap 1.1',\n",
    "                 'scrap 0.9',\n",
    "                 'scrap 0.8',\n",
    "                 'scrap 0.7']\n",
    "    if scenario > 0:\n",
    "            sp2_sd_elas_cn *= float(scenarios[scenario].split()[1])\n",
    "            sp2_sd_elas_rw *= float(scenarios[scenario].split()[1])\n",
    "            sp1_sd_elas_cn *= float(scenarios[scenario].split()[1])\n",
    "            sp1_sd_elas_rw *= float(scenarios[scenario].split()[1])\n",
    "            alloyed_sd_elas_cn *= float(scenarios[scenario].split()[1])\n",
    "            alloyed_sd_elas_rw *= float(scenarios[scenario].split()[1])\n",
    "            \n",
    "            \n",
    "\n",
    "for i in ['TCRC Changes']:\n",
    "    scenarios = ['regional tcrc baseline 20200616',\n",
    "             'tcrc cn 1.0 both 50yoy 20200616',\n",
    "             'tcrc cn 1.0 both 50yoy 100 inc 20200616',\n",
    "             'tcrc cn 1.0 both 50yoy 200 inc 20200616',\n",
    "             'tcrc cn 1.0 both 50yoy 100 dec 20200616',\n",
    "             'tcrc cn 1.0 both 50yoy 200 dec 20200616',\n",
    "             'tcrc cn 0.95 3 yr',\n",
    "             'tcrc cn 0.9 3 yr',\n",
    "             'tcrc cn 0.8 3 yr',\n",
    "             'tcrc cn 0.7 3 yr']\n",
    "    tcrc_years = 23\n",
    "        if scenario > 5:\n",
    "            tcrc_multiplier_cn = float(scenarios[scenario].split()[2])\n",
    "            tcrc_multiplier_rw = 0\n",
    "            if scenarios[scenario].split()[-1] == 'yr':\n",
    "                tcrc_years = float(scenarios[scenario].split()[3])\n",
    "\n",
    "                        \n",
    "for i in ['Scrap SD elasticity']:\n",
    "    scenarios = ['scrap sd elas baseline',\n",
    "             'scrap 0.9',\n",
    "             'scrap 0.8',\n",
    "             'scrap 0.7',\n",
    "             'scrap 1.1',\n",
    "             'scrap 0.9 no2 50yoy',\n",
    "             'scrap 0.9 no2 50yoy 100 inc']\n",
    "    \n",
    "    sp2_sd_elas=price_formation_param.copy().loc['SP2 SD elasticity', 'Value']\n",
    "    sp1_sd_elas=price_formation_param.copy().loc['SP1 SD elasticity', 'Value']\n",
    "    alloyed_sd_elas=price_formation_param.copy().loc['SP Alloy SD elasticity', 'Value']\n",
    "    print('Initial sp2_sd_elas:',sp2_sd_elas)\n",
    "    if scenario > 0:\n",
    "        sp2_sd_elas *= float(scenarios[scenario].split()[1])\n",
    "        sp1_sd_elas *= float(scenarios[scenario].split()[1])\n",
    "        alloyed_sd_elas *= float(scenarios[scenario].split()[1])\n",
    "\n",
    "        sp2_sd_elas_cn = sp2_sd_elas\n",
    "        sp2_sd_elas_rw = sp2_sd_elas\n",
    "        sp1_sd_elas_cn = sp1_sd_elas\n",
    "        sp1_sd_elas_rw = sp1_sd_elas\n",
    "        alloyed_sd_elas_cn = alloyed_sd_elas\n",
    "        alloyed_sd_elas_rw = alloyed_sd_elas\n",
    "        print('New sp2_sd_elas:',sp2_sd_elas)\n",
    "    \n",
    "for i in ['COVID scenarios']:\n",
    "        # COVID Changes: Baseline shocks: minecu2.62, refcu:2.29, gdp2.45\n",
    "    mine_cu_pct_change = pd.Series(0, index=np.arange(2018,2041))\n",
    "    ref_cu_pct_change = pd.Series(0, index=np.arange(2018,2041))\n",
    "    ref_sr_pct_change = pd.Series(0, index=np.arange(2018,2041))\n",
    "    if 'refcu' in scenarios[scenario]:\n",
    "        ref_cu_pct_change.loc[2020] = float(scenarios[scenario].split('refcu')[-1].split()[0])\n",
    "        if 'nsr' not in scenarios[scenario]:\n",
    "            ref_sr_pct_change.loc[2020] = ref_cu_pct_change.loc[2020] * 6.93/2.29 # ratio of 2019 SR and CU changes from ICSG (see 9/4/2020 notes)\n",
    "        print('Ref CU changed:',ref_cu_pct_change.loc[2020])\n",
    "        print('Ref SR changed:',ref_sr_pct_change.loc[2020])\n",
    "    if 'minecu' in scenarios[scenario]:\n",
    "        mine_cu_ratio_2019_2020 = 6.51/2.62 # since normally would give relative to baseline 2020 production instead of 2019 production\n",
    "        mine_cu_pct_change.loc[2020] = float(scenarios[scenario].split('minecu')[-1].split()[0]) * mine_cu_ratio_2019_2020 # positive gives increase\n",
    "        print('Mine CU changed:',mine_cu_pct_change.loc[2020])\n",
    "        \n",
    "    if 'gdpc' in scenarios[scenario]:\n",
    "        gdp_pct_change = float(scenarios[scenario].split('gdpc')[-1].split()[0])\n",
    "        gdp_growth_prediction_base = pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='GDP growth', index_col=0, usecols='BM:BR')\n",
    "        gdp_growth_prediction_base.columns = ['China', 'EU', 'Japan', 'NAM', 'ROW']\n",
    "        gdp_growth_prediction_base.loc[2020] = gdp_growth_prediction_base.loc[2019]+(gdp_growth_prediction_base.loc[2020]-gdp_growth_prediction_base.loc[2019])*gdp_pct_change/2.45\n",
    "        gdp_growth_prediction_base.loc[2021] = gdp_growth_prediction_base.loc[2019]+(gdp_growth_prediction_base.loc[2021]-gdp_growth_prediction_base.loc[2019])*gdp_pct_change/2.45\n",
    "        print('COVID scenario,',gdp_growth_prediction_base)\n",
    "    elif 'allshock' in scenarios[scenario]:\n",
    "        gdp_pct_change = 2.45\n",
    "        gdp_growth_prediction_base = pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='GDP growth', index_col=0, usecols='BM:BR')\n",
    "        gdp_growth_prediction_base.columns = ['China', 'EU', 'Japan', 'NAM', 'ROW']\n",
    "        gdp_growth_prediction_base.loc[2020] = gdp_growth_prediction_base.loc[2019]+(gdp_growth_prediction_base.loc[2020]-gdp_growth_prediction_base.loc[2019])*gdp_pct_change/2.45\n",
    "        gdp_growth_prediction_base.loc[2021] = gdp_growth_prediction_base.loc[2019]+(gdp_growth_prediction_base.loc[2021]-gdp_growth_prediction_base.loc[2019])*gdp_pct_change/2.45\n",
    "        mine_cu_ratio_2019_2020 = 6.51/2.62 # since normally would give relative to baseline 2020 production instead of 2019 production\n",
    "        mine_cu_pct_change.loc[2020] = 2.62 * mine_cu_ratio_2019_2020 # positive gives increase\n",
    "        ref_cu_pct_change.loc[2020] = 2.29\n",
    "        if 'nsr' not in scenarios[scenario]:\n",
    "            ref_sr_pct_change.loc[2020] = ref_cu_pct_change.loc[2020] * 6.93/2.29 # ratio of 2019 SR and CU changes from ICSG (see 9/4/2020 notes)\n",
    "    else:\n",
    "        gdp_growth_prediction_base = pd.read_excel('Data/semis demand/Demand prediction data.xlsx', sheet_name='GDP growth', index_col=0, usecols=np.arange(6))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "551.2px",
    "left": "237px",
    "top": "110.8px",
    "width": "262.383px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": "10",
    "lenVar": "41"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "381.8px",
    "left": "925px",
    "right": "20px",
    "top": "116px",
    "width": "556.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
